## BITAMIN_FINAL_PROJECT
**"법" 관련 네이버 뉴스 기사 크롤링, 군집화 및 키워드 추출**

<br>

**크롤링**
- 1~3일 전 기사까지는 크롤링이 잘 되나, 이 이상으로 넘어가면 정상적으로 되지 않는 경우 발생
- 서비스 제작 시 적어도 **3일 단위로 데이터 업데이트** 할 필요 있음

<br>

**불용어 사전 구축**
- 임베딩 성능 끌어올려 군집화가 원활하게 될 수 있게 하기 위함
- 임베딩 벡터의 차원을 줄여 벡터의 희소성을 완화
- 구축 방법
    - 5일 동안의 기사 참고, 가장 많이 등장한 단어 중 무의미한 단어 제거
        - 해당 기간 가장 많이 등장한 단어 200개 고려
        - 이슈와 직접적으로 관련된 단어들은 불용어 후보에서 제외
        - **서비스 제공 주기에 맞춰(1주일) 계속 업데이트 할 필요 있음**
        - 임베딩 벡터의 차원이 유의미하게 줄어들지 않을 때까지 계속해서 반복
<br>

**군집화**
- TF-IDF Vectorizer 
    - TF-IDF
        - 해당 문장에서는 많이 등장하지만, 전체 문서에서는 적게 사용될수록 분별력 있는 특징이라는 점을 반영
    - hyperparameter
        - min_df : 단어 사전 구축 시 해당 단어가 포함되어야 하는 최소 문서 수 지정
        - analyzer : 학습의 단위를 단어로 설정할 것인지, 글자로 설정할 것인지 지정(word/char)
        - sublinear_tf : TF(단어빈도) 값의 스무딩(smoothing) 여부를 결정(True/False)
            - 단어빈도의 outlier가 있을 때 유용
        - ngram_range : 단어의 묶음 수 지정
            - 단어가 묶여야 의미를 가지는 것들이 있기 때문
        - max_feature : vector의 shape 결정
            - vector가 sparse해지는 문제 해결
- 내부 원소 간 거리 평균이 가장 높게 나온 군집 1개 제거

<br>

**키워드 추출**
- GPT Prompting
    - KeyBert 등 주요 알고리즘으로 시도해봤으나 제대로 키워드 추출이 되지 않음

<br>

**피드백**
- 의의
    - 특정 주제 뉴스 크롤링 시도
    - 텍스트 데이터 벡터화 및 군집화 시도
    - 텍스트 데이터 크롤링 시도
    - GPT Prompting 시도
- 군집화 성능 더 끌어올릴 수 있는 방법 고민
- GPT Prompting을 일관성 있게 만드는 방법 고민
